# -*- coding: utf-8 -*-
"""SI_Lab_3_K-Fold.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XGUoULaqxRLBKyosEmOprp3AWiV3lbJX
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error

df = pd.read_csv("/content/winequality-red.csv")
df.head()

df.isna().sum()

df.shape

corr = df.corr()

plt.figure(figsize=(16, 7))
h_map = sns.heatmap(corr,annot=True)
h_map.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);
plt.show()

df.drop(columns={"residual sugar","free sulfur dioxide","pH"},inplace=True)
df.head()

X = df.drop(columns={"quality"})
y =df["quality"]

X.head()

y.head()

from sklearn.model_selection import StratifiedKFold
import numpy as np
str_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

errors = []

k_fold = KFold(n_splits=5, shuffle=True, random_state=42)
for k, (train_idx,test_idx) in enumerate(k_fold.split(X)):
  X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
  y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

  print(f"K value: {k+1}")
  print(f"Train samples : {X_train.shape[0]}")
  print(f"Test samples : {X_test.shape[0]}")

  model = LinearRegression()
  model.fit(X_train,y_train)

  y_pred = model.predict(X_test)

  mse = mean_squared_error(y_test,y_pred)

  errors.append(mse)

  mae = mean_absolute_error(y_test,y_pred)

  print(f"Mean Squared Error: {mse}")
  print(f"Mean Absolute Error: {mae}")

avg_mse = sum(errors) / len(errors)
print(f"Average mean squared error is {avg_mse}")

plt.figure(figsize=(8,5))
fig , ax = plt.subplots()
color = ['lightblue', 'blue', 'Cyan', 'lightgrey',"darkgrey","royalblue","darkblue"]
ax.bar(range(1,len(errors)+1),errors,color=color)
ax.set_xlabel("Fold")
ax.set_ylabel("MSE")
ax.set_title("MSE for each fold")
plt.show()

# Stratified K-Fold Cross-Validation
for k, (train_idx, test_idx) in enumerate(str_k_fold.split(X, y)):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    print(f"K value: {k+1}")
    print(f"Train samples : {X_train.shape[0]}")
    print(f"Test samples : {X_test.shape[0]}")

    # Initialize Linear Regression model
    model = LinearRegression()
    model.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = model.predict(X_test)

    # Calculate Mean Squared Error and Mean Absolute Error
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    # Store the error values for analysis later
    errors.append(mse)

    print(f"Mean Squared Error: {mse}")
    print(f"Mean Absolute Error: {mae}")

# After the loop, you can analyze the errors list for average MSE/MAE across all folds
average_mse = np.mean(errors)
print(f"Average Mean Squared Error across all folds: {average_mse}")

avg_mse = sum(errors) / len(errors)
print(f"Average mean squared error is {avg_mse}")

plt.figure(figsize=(8,5))
fig , ax = plt.subplots()
color = ['lightblue', 'blue', 'Cyan', 'lightgrey',"darkgrey","royalblue","darkblue"]
ax.bar(range(1,len(errors)+1),errors,color=color)
ax.set_xlabel("Fold")
ax.set_ylabel("MSE")
ax.set_title("MSE for each fold")
plt.show()

# Visualization of MSE for each fold
plt.figure(figsize=(8, 5))
fig, ax = plt.subplots()

# Define color scheme
colors = ['lightblue', 'blue', 'cyan', 'lightgrey', 'darkgrey', 'royalblue', 'darkblue']

# Create bar plot
ax.bar(range(1, len(errors)+1), errors, color=colors[:len(errors)])

# Set labels and title
ax.set_xlabel("Fold")
ax.set_ylabel("Mean Squared Error (MSE)")
ax.set_title("MSE for each fold in Stratified K-Fold")

# Show the plot
plt.show()